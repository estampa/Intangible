{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCMFMJV7K-ag",
        "cellView": "form"
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">‚Üì</font><font color=\"black\" size=\"+3\"> Configuraci√≥ üèóÔ∏è</font></b> \n",
        "\n",
        "%cd /content\n",
        "!rm -rf first_order_model\n",
        "!git clone https://github.com/AliaksandrSiarohin/first-order-model first_order_model\n",
        "!rm -rf sample_data\n",
        "%cd first_order_model\n",
        "!mkdir frames\n",
        "\n",
        "!sed -i 's/sigma = .1 . scale - 1. . 2/sigma = 1.5/g' modules/util.py\n",
        "\n",
        "#!gdown https://drive.google.com/uc?id=1_v_xW1V52gZCZnXgh1Ap_gwA9YVIzUnS\n",
        "!gdown https://drive.google.com/uc?id=1idGJFxGDgbv25ZPFCX-faloByZbPu-it  # face predictor\n",
        "!gdown https://drive.google.com/uc?id=1lnU7KVrZhUZYHFcN4xFGYvh3S45tnZX-  # 512\n",
        "#!wget https://tallerestampa.com/files/intangible/first-order-model-checkpoint-94.pth.tar -O /content/first_order_model/first-order-model-checkpoint-94.pth.tar\n",
        "!wget https://tallerestampa.com/files/intangible/vox-512.yaml -O /content/first_order_model/config/vox-512.yaml\n",
        "\n",
        "!pip install ffmpeg\n",
        "!pip install torchvision==0.7\n",
        "!pip install torch==1.6\n",
        "!pip install imageio-ffmpeg\n",
        "\n",
        "import imageio\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from skimage.transform import resize\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "import io\n",
        "import base64\n",
        "import warnings\n",
        "import os\n",
        "import cv2\n",
        "from google.colab import files\n",
        "from demo import load_checkpoints\n",
        "from demo import make_animation\n",
        "from skimage import img_as_ubyte\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66q21N0NLGl2",
        "cellView": "form"
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">‚Üì</font><font color=\"black\" size=\"+3\"> Pujar el v√≠deo de la locuci√≥ üßëüìπ</font></b> \n",
        "\n",
        "#@markdown **Podeu fer el crop del v√≠deo aqu√≠: https://ezgif.com/crop-video**\n",
        "\n",
        "#@markdown **Podeu convertir el v√≠deo aqu√≠: https://convert-video-online.com**\n",
        "\n",
        "!rm -rf video\n",
        "!mkdir video\n",
        "uploaded = list(files.upload().keys())\n",
        "\n",
        "if len(uploaded) > 1:\n",
        "  raise ValueError('You cannot upload more than one video at a time!')\n",
        "\n",
        "vid = uploaded[0]\n",
        "os.rename(vid, vid.replace(\" \", \"\"))\n",
        "vid = vid.replace(\" \", \"\")\n",
        "!mv -f $vid video/driving.mp4\n",
        "vid = 'video/driving.mp4'\n",
        "\n",
        "fps_of_video = int(cv2.VideoCapture(vid).get(cv2.CAP_PROP_FPS))\n",
        "frames_of_video = int(cv2.VideoCapture(vid).get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KgotDMnL4pN",
        "cellView": "form"
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">‚Üì</font><font color=\"black\" size=\"+3\"> Pujar el retrat ‚úèüòê</font></b> \n",
        "\n",
        "!rm -rf raw_images\n",
        "!mkdir raw_images\n",
        "uploaded = files.upload()\n",
        "\n",
        "i = 0\n",
        "raw_photolist = []\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  os.rename(fn, fn.replace(\" \", \"\"))\n",
        "  fn = fn.replace(\" \", \"\")\n",
        "  pho = \"photo-\" + str(i) + \".\" + fn.split(\".\")[1]\n",
        "  !mv -f $fn raw_images/$pho\n",
        "  raw_photolist.append(pho)\n",
        "  i += 1\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB12II11kF4c",
        "cellView": "form"
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">‚Üì</font><font color=\"black\" size=\"+3\"> Genera el deepfake ‚öô</font></b> \n",
        "\n",
        "!rm -rf video/intermediate video/final\n",
        "!mkdir -p video/intermediate video/final\n",
        "\n",
        "print('Preparing videos and photos for transformation')\n",
        "source_images = []\n",
        "for photoname in raw_photolist:\n",
        "  source_image = imageio.imread('raw_images/' + photoname)\n",
        "  source_image = resize(source_image, (512, 512))[..., :3]\n",
        "  source_images.append(source_image)\n",
        "\n",
        "placeholder_bytes = base64.b64decode('iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mP8/x8AAwMCAO+ip1sAAAAASUVORK5CYII=')\n",
        "placeholder_image = imageio.imread(placeholder_bytes, '.png')\n",
        "placeholder_image = resize(placeholder_image, (512, 512))[..., :3]\n",
        "\n",
        "driving_video = imageio.mimread(vid, memtest=False)\n",
        "driving_video = [resize(frame, (512, 512))[..., :3] for frame in driving_video]\n",
        "\n",
        "def display(source, driving, generated=None):\n",
        "  fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\n",
        "  ims = []\n",
        "  for i in range(len(driving)):\n",
        "    cols = [[placeholder_image], []]\n",
        "    for sourceitem in source:\n",
        "      cols[0].append(sourceitem)\n",
        "    cols[1].append(driving[i])\n",
        "    if generated is not None:\n",
        "      for generateditem in generated:\n",
        "        cols[1].append(generateditem[i])\n",
        "\n",
        "    endcols = []\n",
        "    for thiscol in cols:\n",
        "      endcols.append(np.concatenate(thiscol, axis=1))\n",
        "    \n",
        "    im = plt.imshow(np.vstack(endcols), animated=True) # np.concatenate(cols[0], axis=1)\n",
        "    plt.axis('off')\n",
        "    ims.append([im])\n",
        "  ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n",
        "  plt.close()\n",
        "  return ani\n",
        "\n",
        "generator, kp_detector = load_checkpoints(config_path='config/vox-512.yaml', checkpoint_path='first-order-model-checkpoint-94.pth.tar')\n",
        "\n",
        "#clear_output()\n",
        "print('Start the transformation')\n",
        "videolist = []\n",
        "# predictionlist = []\n",
        "i = 0\n",
        "for source_img in source_images:\n",
        "  videoname = 'result-' + str(i) + '.mp4'\n",
        "  print('Generating ' + videoname)\n",
        "  predictions = make_animation(source_img, driving_video, generator, kp_detector, relative=True)\n",
        "  imageio.mimsave('video/intermediate/' + videoname, [img_as_ubyte(frame) for frame in predictions])\n",
        "  videolist.append(videoname)\n",
        "  # predictionlist.append(predictions)\n",
        "  i += 1\n",
        "\n",
        "clear_output()\n",
        "print('Videos generated.')\n",
        "#HTML(display(source_images, driving_video, predictionlist).to_html5_video())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMYB46yU8Zz4",
        "cellView": "form"
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">‚Üì</font><font color=\"black\" size=\"+3\"> Ajusta el deepfake üß∞</font></b> \n",
        "\n",
        "\n",
        "fps_of_video = int(cv2.VideoCapture(vid).get(cv2.CAP_PROP_FPS))\n",
        "frames_of_video = int(cv2.VideoCapture(vid).get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "!rm -rf frames\n",
        "!mkdir frames\n",
        "\n",
        "# play_video = True #@param {type:\"boolean\"}\n",
        "play_video = True\n",
        "play_html = ''\n",
        "\n",
        "# add_audio = True #@param {type:\"boolean\"}\n",
        "add_audio = True\n",
        "\n",
        "if add_audio == True:\n",
        "  !ffmpeg -y -i $vid -vn -ar 44100 -ac 2 -ab 192K -f mp3 sound.mp3\n",
        "\n",
        "for videoname in videolist:\n",
        "  vidcap = cv2.VideoCapture('video/intermediate/' + videoname)\n",
        "  success,image = vidcap.read()\n",
        "  count = 0\n",
        "  success = True\n",
        "  while success:\n",
        "    cv2.imwrite(\"frames/frame%09d.jpg\" % count, image)\n",
        "    success,image = vidcap.read()\n",
        "    count += 1\n",
        "\n",
        "  frames = []\n",
        "  img = os.listdir(\"frames/\")\n",
        "  img.sort()\n",
        "  for i in img:\n",
        "    frames.append(imageio.imread(\"frames/\"+i))\n",
        "  frames = np.array(frames)\n",
        "  dstvid = 'video/final/' + videoname\n",
        "  imageio.mimsave(dstvid, frames, fps=fps_of_video)\n",
        "\n",
        "  !rm -rf frames\n",
        "  !mkdir frames\n",
        "  \n",
        "  print('Assembly completed for ' + videoname)\n",
        "  \n",
        "  if add_audio == True:\n",
        "    tmpfile = dstvid.replace('.mp4', '-audio.mp4')\n",
        "    !ffmpeg -i sound.mp3 -i $dstvid $tmpfile\n",
        "    !rm -rf $dstvid\n",
        "    !mv -f $tmpfile $dstvid\n",
        "\n",
        "  if play_video == True:\n",
        "    video = io.open(dstvid, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    play_html = play_html + ('<video alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /> </video>'.format(encoded.decode('ascii')))\n",
        "  \n",
        "clear_output()\n",
        "HTML(data=play_html)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPvB7h3IPp6m",
        "cellView": "form"
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">‚Üì</font><font color=\"black\" size=\"+3\"> Descarrega el resultat ‚è¨</font></b> \n",
        "\n",
        "lsinfo = !ls video/final\n",
        "if lsinfo.count('.mp4') == 1:\n",
        "  files.download('video/final/result-0.mp4')\n",
        "else:\n",
        "  !zip -r ../export.zip video/final\n",
        "  files.download('../export.zip')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}